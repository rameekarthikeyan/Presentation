panel = panel.smooth, rows = 1)
require(graphics)
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ am | as.factor(cyl), data = mtcars,
panel = panel.smooth, rows = 1)
require(graphics)
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ cyl | as.factor(am), data = mtcars,
panel = panel.smooth, rows = 1)
require(graphics)
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ hp | as.factor(am), data = mtcars,
panel = panel.smooth, rows = 1)
require(graphics)
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ carb | as.factor(am), data = mtcars,
panel = panel.smooth, rows = 1)
summary(mtcars)
nrow(mtcars)
head(mtcars$vs, mtcars$am)
head(mtcars$vs)
mtcars$vs
mtcars$am
?mtcars
library(data.table)
newDT <- data.table(mtcars)
manualDT <- data.table[am = 0]
manualDT <- data.table[am == 0]
head(newDT)
manualDT <- data.table['am' == 0]
manualDT <- data.table['am' = 0]
setkey(newDT, am)
manualDT <- data.table[0]
manualDT <- data.table['0']
manualDT <- newDT['0']
manualDT <- newDT[0]
manyalDT
manualDT
manualDT <- newDT[am=0]
manualDT <- newDT[1]
manualDT
manualDT <- newDT['1']
manualDT <- newDT[am = 0]
manualDT <- newDT[am == 0]
manualDT
manualDT <- newDT[am == 1]
autoDT <- newDT[am == 1]
autoDT
autosubDT <- autoDT[,!am]
autosubDT
autosubDT <- autoDT[][!am]
autosubDT <- autoDT[][,!am]
autosubDT
autosubDT <- autoDT[,!"am", with=FALSE]
autosubDT
lmat <- lm(mpg ~., data = autosubDT)
summary(lmat)
lmat11 <- lm(mpg ~cyl, data = autosubDT)
summary(lmat11)
lmat11 <- lm(mpg ~disp, data = autosubDT)
summary(lmat11)
lmat11 <- lm(mpg ~hp, data = autosubDT)
summary(lmat11)
lmat11 <- lm(mpg ~wt, data = autosubDT)
summary(lmat11)
lmat11 <- lm(mpg ~qsec, data = autosubDT)
summary(lmat11)
summary(lmat)
data(InsectSprays)
summary(InsectSprays)
head(InsectSprays)
tail(InsectSprays)
quit()
library(data.table)
library(datasets)
data(mtcars)
summary(mtcars)
newDT <- data.table(mtcars)
lineramodel1 <- lm(mpg ~ as.factor(am), data = newDT)
summary(lineramodel1)
lineramodel1 <- lm(mpg ~ as.factor(am) - 1, data = newDT)
summary(lineramodel1)
plot(lineramodel1)
lineramodel2 <- lm(mpg ~ am, data = newDT)
summary(lineramodel2)
lineramodel2 <- lm(mpg ~ am - 1, data = newDT)
summary(lineramodel2)
colclasses(newDT)
ncol(newDT)
?data.table
newDT
?mtcars
class(newDT)
class(newDT$am)
class(newDT$vs)
class(newDT$am)
class(newDT$am) <- factor
summary(lineramodel1)$coef
summary(lineramodel1)$coeff
summary(lineramodel1)$sigma
summary(lineramodel1)$rsquared
?sigma
summary(lineramodel1)$r
summary(lineramodel1)$R
quit()
?plot
library(MASS)
data(shuttle)
head(shuttle)
newddt <- data.table(shuttle)
library(data.table)
install.packages("Rcpp")
library(data.table)
newddt <- data.table(shuttle)
?expr
?expression
?data.table
updt <- newddt[, z:= 1]
head(updt)
updt1 <- newddt[, z:= 1, by = use]
head(updt1)
tail(updt1)
updt2 <- newddt[, z:= {use == 'auto'}]
head(updt2)
tail(updt2)
updt3 <- newddt[, z:= {if use == 'auto' return 1 else return 0}]
updt3 <- newddt[, z:= {if (use == 'auto') return 1 else return 0}]
?IF
?if
updt3 <- newddt[, z:= {if (use == 'auto') 1 else 0}]
tail(updt3)
head(updt3)
updt4 <- newddt[, z:= {ifesle(use == 'auto',1,0)}]
updt4 <- newddt[, z:= {ifelse(use == 'auto',1,0)}]
head(updt4)
tail(updt4)
newft1 <- glm(updt4$z ~updt4$wind, family="binomial")
summary(newft1)
0.25131/0.03181
?glm
newft2 <- glm(updt4$z ~updt4$wind-1, family="binomial")
summary(newft2)
hedodd <- 0.158/(1-0.158)
talodd <- 0.113/(1-0.113)
hedodd/talodd
class(updt4$wind)
newft3 <- glm(updt4$z ~updt4$wind + magn-1, family="binomial")
newft3 <- glm(updt4$z ~updt4$wind + updt4$magn-1, family="binomial")
summary(newft3)
class(updt4$magn)
nrow(updt4)
0.201/(1-0.201)
0.164/(1-0.164)
0.2515645/0.1961722
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(y,x)
plot(x,y)
x1 <- -5:0
ft1 <- lm(y~x1)
y1 <- c(y[1:6])
y1
ft1 <- lm(y1~x1)
abline(ft1)
x2 <- 0:5
y12 <- c(y[6:11])
ft2 <- lm(y12~x2)
abline(ft2)
summary(ft2)
ft1 <- lm(y1~x1-1)
abline(ft1)
ft2 <- lm(y12~x2-1)
abline(ft2)
summary(ft2)
exp(0.2513)/exp(0.2831)
exp(0.3635)/exp(0.3955)
data(InsectSprays)
head(InsecSprays)
head(InsectSprays)
InsectSprays$count
class(InsectSprays$spray)
ft <-glm(spray~count, data = InsectSprays, family="poisson")
ft <-glm(as.factor(spray)~count, data = InsectSprays, family="poisson")
nrow(InsectSprays)
InsectSprays$spray
ft <-glm(factor(spray)~count, data = InsectSprays, family="poisson")
ndtt <- data.table(InsectSprays)
dt11 <- ndtt[,z:={ifelse(spray=='A',1,ifelse(spray=='B',2,ifelse(spray=='C',3,0)))}]
head(dt11)
tail(dt11)
head(dt11. 10)
head(dt11, 30)
dt11 <- ndtt[,z:={ifelse(spray=='A',1,ifelse(spray=='B',2,ifelse(spray=='C',3,ifelse(spray=='D',4,ifelse(spray=='E',5,6)))))}]
head(dt11, 30)
tail(dt11, 30)
newftt <- glm(dt11$z~dt11$count, family = "poisson")
summary(newftt)
exp(-0.010387)
newftt <- glm(factor(dt11$z)~dt11$count, family = "poisson")
newfts <- glm(count~factor(spray), data = InsectSprays,family = "poisson")
summary(newfts)
exp(2.67415)/exp(0.05588)
newfts <- glm(count~factor(spray)-1, data = InsectSprays,family = "poisson")
summary(newfts)
exp(2.67415)/exp(2.73003)
quit()
quit()
library(lubridate)
dat = read.csv("C:/Users/Swetha/Documents/DataScience/Practical Machine LearningaData.csv")
dat = read.csv("C:/Users/Swetha/Documents/DataScience/Practical Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
head(dat)
head(tstrain)
tstest = ts(testing$visitsTumblr)
head(tstest)
tail(tstrain)
tt <- bats(tstrain)
library(forecast)
tt <- bats(tstrain)
plot(forecast(tt))
ts <- bats(tstest)
lines(ts, col="green")
head(ts)
plot(forecast(ts))
head(forecast(tt))
plot(forecast(tt))
lines(tstest, col="green")
forecast(tt)
head(tstest)
head(tstest,10)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
libray(caret)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
tr <- svm(CompressiveStrength~., data = training)
tt <- predict(tr,testing)
sqrt(sum((tt - testing$CompressiveStrength)^2)/nrow(testing))
install.packages("glmmLasso")
library(glmmLasso)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
tr <- glmmLasso(CompressiveStrength~., data = training)
head(training)
colnames(training)
nufn <- function(x)
{}
nufn <- function(x)
{
paste0(x,"+")
}
tryl <- lapply(colnames(training), nufn)
tryl
unlist(tryl)
tryl
c(unlist(tryl))
set.seed(233)
tr <- glmmLasso(CompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + CoarseAggregate + FineAggregrate + Age, data = training)
tr <- glmmLasso(CompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + CoarseAggregate + FineAggregate + Age, data = training)
tr <- glmmLasso(CompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + CoarseAggregate + FineAggregate + Age, rnd = list(team=~ 1),data = training)
tr <- glmmLasso(CompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + CoarseAggregate + FineAggregate + Age, rnd = list(CompressiveStrength=~ 1),data = training)
install.packages("shiny")
library(shiny)
quit()
data(sunspot.year)
head(sunspot.year)
nrow(sunspot.year)
length(sunspot.year)
data(sunspot.month)
head(sunspot.month)
length(sunspot.month)
289*12
data(sunspots)
length(sunspots)
head(sunspots)
data(UCBAdmissions)
head(UCBAdmissions)
summary(UCBAdmissions)
str(UCBAdmissions)
class(UCBAdmissions)
newdt <- data.table(UCBAdmissions)
library(data.table)
newdt <- data.table(UCBAdmissions)
head(newdt)
tail(newdt)
nrow(newdt)
newdt
nrow(UCBAdmissions)
length(UCBAdmissions)
UCBAdmissions
data(rivers)
head(rivers)
class(rivers)
length(rivers)
data(rock)
head(rock)
nrow(rock)
rock
library(randomForest)
pdtr <- randomForest(perm ~ .,data = rock)
summary(pdtr)
pdtr
pdtr <- randomForest(as.factor(perm) ~ .,data = rock)
pdtr
tr <- lm(as.factor(perm)~., data = rock)
data(quakes)
head(quakes)
nrow(QUAKES)
nrow(quakes)
tail(quakes)
pairs(quakes, main = "Fiji Earthquakes, N = 1000", cex.main = 1.2, pch = ".")
max(quakes$mag)
which.max(quakes$mag)
quakes[152,]
newmof <- randomForest(mag ~ lat + long + depth, data = quakes)
newmof
newtet <- data.frame("-20.0","189", "50")
predict(newmof, newtet)
newtet <- data.frame(lat = "-20.0",long"189", depth ="50")
newtet <- data.frame(-20.0,189,50)
predict(newmof, newtet)
newtet
newtet <- data.frame("lat" =-20.0,"long"=189,"depth"=50)
newtet
predict(newmof, newtet)
quit()
setwd("~/DataScience/Developing Data Products/Earthquake")
dir()
runApp()
library(shiny)
runApp()
library(shinyapps)
deployApp()
terminateApp("courseproject")
terminateApp("CourseProject")
## Slide 2
library(slidify)
setwd("~/DataScience/Developing Data Products/CourseProject")
author("Earthquake presentation")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
---
title       : Application for summarizing number of Earthquakes
subtitle    :
author      :
job         :
framework   : io2012   # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      #
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---
## Why this app is needed?
* This app provides a visual picture as well as number of the Earthquakes happened in the world from the period of January 1, 2000 to present per hemisphere.
* This app also provides the place of highest magnitude Earthquake happened in the corresponding hemisphere and the value of highest magnitude.
--- .class #id
## How this app works?
* Data is downloaded from the USGS website and then stored in local directory
* Data is then read into R
* Based on user inputs, the minimum magnitude earthquake scale and hemisphere are used to identify the subset of the data
* Subset of the data is then used to return the number of earthquakes, highest magnitude and place of highest magnitude earthquake
---
## R coding
```{r}
eqdata <- read.csv("./Data/Earthquake.cvs")
head(eqdata, 4)
```
---
## R coding (continued)
```{r}
mapp <- data.frame("v1" = c("Eastern","Western","Northern","Southern"), "v2"=c("longitude>=0","longitude<0","latitude>=0", "latitude<0"))
rs <-mapp[mapp$v1 == "Western",]
extext <- levels(rs$v2)[rs$v2]
subdat <- subset(eqdata, eval(parse(text = extext)))
max(subdat$mag)
nrow(subdat[subdat$mag>=7,])
```
---
## References
slidify("index.Rmd")
---
title       : Application for summarizing number of Earthquakes
subtitle    :
author      :
job         :
framework   : io2012   # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      #
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---
## Why this app is needed?
* This app provides a visual picture as well as number of the Earthquakes happened in the world from the period of January 1, 2000 to present per hemisphere.
* This app also provides the place of highest magnitude Earthquake happened in the corresponding hemisphere and the value of highest magnitude.
--- .class #id
## How this app works?
* Data is downloaded from the USGS website and then stored in local directory
* Data is then read into R
* Based on user inputs, the minimum magnitude earthquake scale and hemisphere are used to identify the subset of the data
* Subset of the data is then used to return the number of earthquakes, highest magnitude and place of highest magnitude earthquake
---
## R coding
```{r}
eqdata <- read.csv("./Data/Earthquake.cvs")
head(eqdata, 4)
```
---
## R coding (continued)
```{r}
mapp <- data.frame("v1" = c("Eastern","Western","Northern","Southern"), "v2"=c("longitude>=0","longitude<0","latitude>=0", "latitude<0"))
rs <-mapp[mapp$v1 == "Western",]
extext <- levels(rs$v2)[rs$v2]
subdat <- subset(eqdata, eval(parse(text = extext)))
max(subdat$mag)
nrow(subdat[subdat$mag>=7,])
```
---
## References
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
library(shinyapps)
terminateApp("Earthquake")
deployApp()
setwd("~/DataScience/Developing Data Products/Earthquake")
deployApp()
terminateApp("Earthquake")
deployApp()
setwd("~/DataScience/Developing Data Products/CourseProject/Earthquake presentation")
library(shinyapps)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
quit()
